########
# Started: 2022-11-26
# by Rodrigo García-López for Dr. Arias laboratory at IBt, UNAM, Cuernavaca, Mexico.
# Under GNU GPLv3 license
########
# All available sequences from BQ.1, BA.5.6.2 and BW.1

cat gisaid*.fasta > gisaid_2022-11-07.fasta

########
# Linearize fasta
perl -ne 'chomp;if($_=~/^>/){print "\n$_\n"}else{print $_}' gisaid_2022-11-07.fasta| tail +2 >gisaid_2022-11-07_linear.fasta

# Fix some errors where > is found mid-sequence (47 cases). Fasta is already linear (single-line sequence)
sed -e 's/\([ATCG]\)>/\1\n>/' gisaid_2022-11-07_linear.fasta >gisaid_2022-11-07_linear_fix.fasta

########
# MAFFT failed with very ambiguous sequences (high N%) but we must filter them externally since the --maxambiguous 
# removes Ns from the output alignment. Thus, we first require a list of good files
# Create a comparison table with ATCG contents using seqtk (requires previous installation)
printf "Genome\tLength\tA\tC\tG\tT\t2amb\t3amb\t4amb(N)\tCpG\ttv\tts\tCpG-ts\n" > gisaid_2022-11-07.fasta_linear_fix_atcg_contents.tsv

########
seqtk comp gisaid_2022-11-07_linear_fix.fasta >> gisaid_2022-11-07.fasta_linear_fix_atcg_contents.tsv
# Determine good and bad sequences (with N% < 10)
printf "Genome\tLength\tA\tC\tG\tT\t2amb\t3amb\t4amb(N)\tCpG\ttv\tts\tCpG-ts\n" >gisaid_2022-11-07.fasta_linear_fix_atcg_contents-good.tsv
awk 'NR > 1{Np = $9*100/$2;if(Np<10){print $0}}' gisaid_2022-11-07.fasta_linear_fix_atcg_contents.tsv >>gisaid_2022-11-07.fasta_linear_fix_atcg_contents-good.tsv
printf "Genome\tLength\tA\tC\tG\tT\t2amb\t3amb\t4amb(N)\tCpG\ttv\tts\tCpG-ts\n" >gisaid_2022-11-07.fasta_linear_fix_atcg_contents-bad.tsv
awk 'NR > 1{Np = $9*100/$2;if(Np>=10){print $0}}' gisaid_2022-11-07.fasta_linear_fix_atcg_contents.tsv >>gisaid_2022-11-07.fasta_linear_fix_atcg_contents-bad.tsv
# Extract all "good" sequences from the fasta (this will only work for linear fastas)
# seqtk subseq gisaid_2022-11-07_linear_fix.fasta <(tail +2 gisaid_2022-11-07.fasta_linear_fix_atcg_contents-good.tsv|cut -f 1) >2022_08_29_DB_MexCov2_filt.tsv # DEPRECATED: This creates more items than requested.
grep -A 1 -wFf <(tail +2 gisaid_2022-11-07.fasta_linear_fix_atcg_contents-good.tsv|cut -f 1) gisaid_2022-11-07_linear_fix.fasta >gisaid_2022-11-07_linear_fix_filt.fasta

# Used for aligning SARS-CoV-2 sequences using Wuhan Wu-h1 reference with a local MAFFT installation
# mafft --6merpair --thread 6 --preservecase --addtotop 1 --kimura 1 --maxambiguous 0.1 --addfragments test.fasta NC_045512.2.fasta >out1.fasta
# For this, ~40 GB were required and lasted >2h
# mafft --thread 12 --preservecase --kimura 1 --maxambiguous 0.1 --addtotop 2022_08_29_DB_MexCov2_fix.fasta --6merpair NC_045512.2.fasta >MAFFT_aligned.fasta
# DEPRECATED: The last command changed Ns into ----n. If we avoid using --maxambiguous 0.1, we cannot longer use the N % filter but we may keep Ns, so I'd rather filter N %s downstream.
# Use this command to align (this is the fastest way I managed to find but is memory-heavy):
mafft --thread 12 --preservecase --kimura 1 --addtotop gisaid_2022-11-07_linear_fix_filt.fasta --6merpair ref_NC_045512.2.fasta >MAFFT_aligned.fasta
# --6merpair	Distance is calculated based on the number of shared 6mers. Default: on
# --kimura	Score matrix for nucleotide alignment (1, 20, 200).
# --maxambiguous	 max freq of Ns or such characters
# --addfragments	add unaligned sequences to an existing MSA. It assumes that each new sequence was derived from a branch in the tree of an existing alignment. It does not consider the relationship among the sequences to be added.
# --addtotop	Use only the top sequence as reference
# --preservecase	preseve uppercase or lowercase

# Now, linearize the resulting fasta (one seq per line)
perl -ne 'chomp;if($_=~/^>/){print "\n$_\n"}else{print $_}' MAFFT_aligned.fasta| tail +2 >MAFFT_aligned_linear.fasta

# Create a list of GISAID IDs
grep "^>" MAFFT_aligned_linear.fasta|cut -d"|" -f 2 >GISAID_ID.txt

# Create two-way table input
paste - - -d"\t" <MAFFT_aligned_linear.fasta >analysis_seq_input-pre.tsv


# UPDATE 2022-09-07: Remove incomplete genomes
# It seems some ~55 sequences in gisaid were generated by sanger, and are thus only genomic fragments. These were aligned by MAFFT but should be removed from the downstream analyses.
cut -f 2 analysis_seq_input-pre.tsv| sed 's/[^-]//g'|awk '{print length}' >X.temp & # Count each present Nt separately
cut -f 2 analysis_seq_input-pre.tsv| sed 's/[^A]//g'|awk '{print length}' >A.temp &
cut -f 2 analysis_seq_input-pre.tsv| sed 's/[^T]//g'|awk '{print length}' >T.temp &
cut -f 2 analysis_seq_input-pre.tsv| sed 's/[^C]//g'|awk '{print length}' >C.temp &
cut -f 2 analysis_seq_input-pre.tsv| sed 's/[^G]//g'|awk '{print length}' >G.temp &
cut -f 2 analysis_seq_input-pre.tsv| sed 's/[^N]//g'|awk '{print length}' >N.temp &
# Create a single table to summarize this
printf "Genome\t-\tA\tT\tC\tG\tN\n" >Genome_nt_contents.tsv
paste <(cut -f 1 analysis_seq_input-pre.tsv) X.temp A.temp T.temp C.temp G.temp N.temp >>Genome_nt_contents.tsv
rm *.temp # delete temporary tables
# Now, get how many have more than 10K gaps (incomplete genomes)
awk 'BEGIN { FS = "\t" }; {if($2>10000){print $0}}' Genome_nt_contents.tsv >incomplete_items_post-mafft.tsv
# Finally, create a new version of the actual input table for the analyses
cut -f 1 incomplete_items_post-mafft.tsv|grep -wvFf - analysis_seq_input-pre.tsv >analysis_seq_input.tsv
# END of UPDATE

zip analysis_seq_input.zip analysis_seq_input.tsv # and zip it

# Prepare Metadata
# head -n 1 01_data/gisaid_hcov-19_2022_11_07_15_ba562_meta.tsv >01_data/meta_all.tsv
# for i in $(find 01_data -name "*meta.tsv");do echo 'tail +2 '$i' >>01_data/meta_all.tsv';done|bash
sed 's/,/\t/g' 01_data/gisaid_hcov-19_MexCov2_Template.csv >01_data/gisaid_hcov-19_MexCov2_Template.tsv
Rscript preFilter_raw_metatable.R
Rscript Filter_preTable.R

# Load the table, filter repeated items and create a matrix with each Nt as columns
Rscript Analyze_MexSARS_indels.R
# ### #NOTE# ### Even though this actually worked, it was too memory-intensive to work for downstream steps as the table requires ~40GB of memory (local computer has 32GB RAM +10GB swap)

# Create longitudinal pdfs
pdftk Week_BQ.1-World/*.pdf output Week_BQ.1-World.pdf
pdftk Week_BA.5.6.2-World/*.pdf output Week_BA.5.6.2-World.pdf
pdftk Week_BW.1-World/*.pdf output Week_BW.1-World.pdf
pdftk Week_BA.5.6.2-Mexico/*.pdf output Week_BA.5.6.2-Mexico.pdf
pdftk Week_BA.5.6.2-Except_Mexico/*.pdf output Week_BA.5.6.2-Except_Mexico.pdf
pdftk Week_BW.1-Mexico/*.pdf output Week_BW.1-Mexico.pdf
pdftk Week_BQ.1-Except_Mexico/*.pdf output Week_BQ.1-Except_Mexico.pdf
pdftk Week_BQ.1-Mexico/*.pdf output Week_BQ.1-Mexico.pdf

# Now, process all the resulting table to get the consensus per variant in each category
for i in $(find ./02_Analyses/ -name "*.tsv"|grep -v "position");do echo 'Rscript Get_consensus.R '$i' '${i%.tsv}_cons'';done|bash
# Next, the same tables are used to get all mutations
for i in $(find ./02_Analyses/ -name "*.tsv"|grep -v "position\|cons");do echo 'Rscript Get_mutations.R '$i' '${i%.tsv}_allMuts'';done >multi.sh
# run this in parallel
split -a 2 -d -l 14 --additional-suffix .sh multi.sh run_parallel_
# Now, create a maximum set list with all mutations, derreplicate and sort it
cat 02_Analyses/Lineage_World/*allMuts.tsv|cut -f 1|sort| uniq >allMuts_inSet.tsv
# Use this to create a table per 02_folder so that weeks and variants can be compared easily per mutations
for i in $(ls -d 02_Analyses/*/);do echo 'Rscript Mutations_table.R '$i' _allMuts.tsv allMuts_inSet.tsv';done|bash
print("End of execution")




